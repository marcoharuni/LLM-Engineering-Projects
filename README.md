<div align="center">

<h1 style="background: linear-gradient(90deg,#00c6ff,#0072ff); -webkit-background-clip: text; -webkit-text-fill-color: transparent; font-size:48px;">
ğŸš€ LLM Engineering Projects
</h1>

<a href="https://x.com/marcoharuni">
  <img src="https://img.shields.io/badge/X-@marcoharuni-000000?style=for-the-badge&logo=x&logoColor=white"/>
</a>
&nbsp;&nbsp;
<a href="https://youtube.com/@marcoharuni">
  <img src="https://img.shields.io/badge/YouTube-marcoharuni-ff0000?style=for-the-badge&logo=youtube&logoColor=white"/>
</a>

<br><br>

<img src="assets/banner.png" width="1000"/>

<p>
<b>From mathematics to trillion-parameter systems. Build modern LLMs from scratch.</b>
</p>

</div>

---

## ğŸŒˆ Prerequisites

<table width="100%" style="font-size:18px;">
<tr>
<th>â­</th>
<th>Topic</th>
<th>Resource</th>
</tr>

<tr>
<td align="center">1</td>
<td><b>Python, Mojo, Rust, C/C++</b></td>
<td align="center">[Link]()</td>
</tr>

<tr>
<td align="center">2</td>
<td><b>High School Mathematics (Algebra, Probability, Calculus, Geometry)</b></td>
<td align="center">[Link]()</td>
</tr>

<tr>
<td align="center">3</td>
<td><b>Neural Networks & Deep Learning Fundamentals</b></td>
<td align="center">[Link]()</td>
</tr>

<tr>
<td align="center">4</td>
<td><b>PyTorch</b></td>
<td align="center">[Link]()</td>
</tr>

<tr>
<td align="center">5</td>
<td><b>GPU Programming (CUDA basics)</b></td>
<td align="center">[Link]()</td>
</tr>

<tr>
<td align="center">6</td>
<td><b>Pandas, NumPy, Matplotlib</b></td>
<td align="center">[Link]()</td>
</tr>

<tr>
<td align="center">7</td>
<td><b>CS Fundamentals (Data Structures & Algorithms)</b></td>
<td align="center">[Link]()</td>
</tr>

<tr>
<td align="center">8</td>
<td><b>Computer Architecture (GPU, CPU, Memory Hierarchy)</b></td>
<td align="center">[Link]()</td>
</tr>
</table>

---

## ğŸ“š List of Projects

<details open>
<summary><b>Click to expand projects</b></summary>

<br>

<table width="100%" style="font-size:20px;">
<tr>
<th width="10%">S/N</th>
<th width="40%">Project</th>
<th width="15%">Video</th>
<th width="15%">Blog</th>
<th width="20%">Notebook</th>
</tr>

<tr>
<td align="center"><b>01</b></td>
<td><b>Tokenization & Embeddings</b></td>
<td align="center">â–¶ï¸</td>
<td align="center">ğŸ“</td>
<td align="center">
<img src="https://colab.research.google.com/assets/colab-badge.svg" height="40"/>
</td>
</tr>

<tr>
<td align="center"><b>02</b></td>
<td><b>Positional Embeddings</b></td>
<td align="center">â–¶ï¸</td>
<td align="center">ğŸ“</td>
<td align="center">
<img src="https://colab.research.google.com/assets/colab-badge.svg" height="40"/>
</td>
</tr>

</table>

</details>

---

## ğŸ§  The Researcher's Mindset

**Ablate Everything** â€” Don't trust paper claims. Break the code. Swap RoPE for ALiBi mid-training. Does it die?

**Visualize Religiously** â€” Log attention maps to W&B every 100 steps. Plot activation histograms by layer.

**Data > Architecture > Hyperparams** â€” Spend 50% of time on data quality, 30% on architecture, 20% on hyperparameters.

**Scale Extrapolation** â€” Train 1M â†’ 10M â†’ 100M â†’ 1B. Fit scaling laws.

**Emergency Brakes** â€” NaN detection. Gradient norm tracking. Kill job if loss > 100 or NaN.

---

## ğŸ“– Citation

```bibtex
@misc{haruni2026llmengineering,
  author       = {Marco Haruni},
  title        = {LLM Engineering Projects: From Zero to Trillion-Parameter Training},
  year         = {2026},
  publisher    = {GitHub},
  howpublished = {\url{https://github.com/marcoharuni/LLM-Engineering-Projects }}
}
